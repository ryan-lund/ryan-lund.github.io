<!DOCTYPE html>
<html ang="en">
<head>
    <meta charset="UTF-8">
    <title>Ryan Lund | bFloat16 for Gemmini</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <link rel="stylesheet" type="text/css" href="css/index.css"/>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/typed.js/2.0.8/typed.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
</head>
<body class="vh-100">
    <h1> 16-Bit Brain Floating Point for Gemmini</h1>
    <h2>Abstract</h2>
    <p>
    Pioneered for use on Google's machine learning (ML) specific architecture [1], 16-bit brain floating point (BF16) is a novel format that promises resource benefits with minimal performance impacts compared to the traditional IEEE 32-bit floating point (FP32). With these benefits in mind, BF16 has been slowly trickling into ML oriented processors and accelerators such as Armv8-A, the Habana HL series, and the aforementioned Google Tensor Processing Unit (TPU). This paper explores the process of adding support for BF16 to the Gemmini systolic array generator [2]. Additionally, it discusses the impacts of BF16 on accuracy, area utilization, and power consumption for Gemmini generated systolic arrays coupled with a Rocket Core in-order [3] processor
    </p>
    <h2>Paper</h2>
        <a href="https://github.com/ryan-lund/ryan-lund.github.io/blob/master/doc/Gemmini-bFloat.pdf">Full Paper</a>
    <h2>Code</h2>
    <ul>
        <li><a href="https://github.com/TsaiAnson/chipyard">Chipyard Fork (shared with EE241B project)</a></li>
        <li><a href="https://github.com/ryan-lund/gemmini">Gemmini Fork</a></li>
        <li><a href="https://github.com/ryan-lund/gemmini-rocc-tests">Gemmini Rocc Tests Fork</a></li>
        <li><a href="https://github.com/ryan-lund/berkeley-softfloat-3">Softfloat Fork</a></li>
        <li><a href="https://colab.research.google.com/drive/10ePbHlkJxp5Jfq8yq2jpa6k_wlyBCSf5?usp=sharing">bFloat Model Generation for FireSim</a></li>
        <li><a href="https://colab.research.google.com/drive/1F7H9vmAJubkVT9JtzfQnOQpPRv04MMwB?usp=sharing">Model Generation for TF Accuracy</a></li>
    </ul>

</body>
</html>